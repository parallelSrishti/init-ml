{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Model.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "faced-insider"
      },
      "source": [
        "# importing required libraries\n",
        "import nltk\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import pickle"
      ],
      "id": "faced-insider",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incorporate-movement"
      },
      "source": [
        "# read the dataset\n",
        "train = pd.read_csv(\"./train.txt\", delimiter=';', header=None, names=['sentence','label'])\n",
        "test = pd.read_csv(\"./test.txt\", delimiter=';', header=None, names=['sentence','label'])\n",
        "val = pd.read_csv(\"./val.txt\", delimiter=';', header=None, names=['sentence','label'])"
      ],
      "id": "incorporate-movement",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "organic-slovak",
        "outputId": "875d68fc-1276-4ec5-d90c-bc48e9441a46"
      },
      "source": [
        "df_data = pd.concat([train, test,val])\n",
        "df_data"
      ],
      "id": "organic-slovak",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>im having ssa examination tomorrow in the morn...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>i constantly worry about their fight against n...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>i feel its important to share this info for th...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>i truly feel that if you are passionate enough...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence    label\n",
              "0                               i didnt feel humiliated  sadness\n",
              "1     i can go from feeling so hopeless to so damned...  sadness\n",
              "2      im grabbing a minute to post i feel greedy wrong    anger\n",
              "3     i am ever feeling nostalgic about the fireplac...     love\n",
              "4                                  i am feeling grouchy    anger\n",
              "...                                                 ...      ...\n",
              "1995  im having ssa examination tomorrow in the morn...  sadness\n",
              "1996  i constantly worry about their fight against n...      joy\n",
              "1997  i feel its important to share this info for th...      joy\n",
              "1998  i truly feel that if you are passionate enough...      joy\n",
              "1999  i feel like i just wanna buy any cute make up ...      joy\n",
              "\n",
              "[20000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "accepting-ceremony",
        "outputId": "833d62e2-bdc1-4543-ac50-f734c78670f0"
      },
      "source": [
        "df_data.to_csv (r'exportdata.txt', index=False)\n",
        "dt_data =  pd.read_csv(\"exportdata.txt\")\n",
        "dt_data.head"
      ],
      "id": "accepting-ceremony",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                 sentence    label\n",
              "0                                i didnt feel humiliated  sadness\n",
              "1      i can go from feeling so hopeless to so damned...  sadness\n",
              "2       im grabbing a minute to post i feel greedy wrong    anger\n",
              "3      i am ever feeling nostalgic about the fireplac...     love\n",
              "4                                   i am feeling grouchy    anger\n",
              "...                                                  ...      ...\n",
              "19995  im having ssa examination tomorrow in the morn...  sadness\n",
              "19996  i constantly worry about their fight against n...      joy\n",
              "19997  i feel its important to share this info for th...      joy\n",
              "19998  i truly feel that if you are passionate enough...      joy\n",
              "19999  i feel like i just wanna buy any cute make up ...      joy\n",
              "\n",
              "[20000 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twelve-documentary"
      },
      "source": [
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english', ngram_range=(1,1), tokenizer = token.tokenize)\n",
        "text = cv.fit_transform(dt_data['sentence'])"
      ],
      "id": "twelve-documentary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dominant-group",
        "outputId": "ac22d527-60d9-46b9-c7db-5d7bca6dc95b"
      },
      "source": [
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(text,dt_data['label'], test_size=0.30, random_state=5)\n",
        "\n",
        "# get the shape of train and test split.\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "id": "dominant-group",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14000, 16798), (6000, 16798), (14000,), (6000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "retained-onion",
        "outputId": "f0a9eeb3-50a1-434e-dde1-5848a8d18ab7"
      },
      "source": [
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train, y_train)"
      ],
      "id": "retained-onion",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "searching-doubt"
      },
      "source": [
        "predicted = mnb.predict(X_test)"
      ],
      "id": "searching-doubt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inner-electronics"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "id": "inner-electronics",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fluid-printing"
      },
      "source": [
        "acc_score = metrics.accuracy_score(predicted,y_test)\n",
        "prec_score = precision_score(y_test,predicted, average='macro')\n",
        "recall = recall_score(y_test, predicted,average='macro')\n",
        "f1 = f1_score(y_test,predicted,average='macro')\n",
        "matrix = confusion_matrix(y_test,predicted)"
      ],
      "id": "fluid-printing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stainless-service",
        "outputId": "e2fe5544-d70f-4205-b397-711b397dfa02"
      },
      "source": [
        "print(str('Accuracy: '+'{:04.2f}'.format(acc_score*100))+'%')\n",
        "print(str('Precision: '+'{:04.2f}'.format(prec_score*100))+'%')\n",
        "print(str('Recall: '+'{:04.2f}'.format(recall*100))+'%')\n",
        "print('F1 Score: ',f1)\n",
        "print(matrix)"
      ],
      "id": "stainless-service",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 77.53%\n",
            "Precision: 82.71%\n",
            "Recall: 58.59%\n",
            "F1 Score:  0.6191209661316305\n",
            "[[ 512   14   92    2  179    0]\n",
            " [  26  430   98    2  144    1]\n",
            " [  12   12 1890   23   95    0]\n",
            " [   7    5  241  162   74    0]\n",
            " [  13   11   83    2 1644    1]\n",
            " [   4   29   92    2   84   14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "surgical-imaging"
      },
      "source": [
        "import joblib"
      ],
      "id": "surgical-imaging",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dramatic-steel",
        "outputId": "5efbc878-9667-4b06-f9d2-510720d7e53a"
      },
      "source": [
        "joblib.dump(mnb, 'model.pkl')"
      ],
      "id": "dramatic-steel",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stainless-baker"
      },
      "source": [
        "model = open('model.pkl','rb')\n",
        "mnb = joblib.load(model)"
      ],
      "id": "stainless-baker",
      "execution_count": null,
      "outputs": []
    }
  ]
}